{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78773ee8",
   "metadata": {},
   "source": [
    "# **LIMPIEZA Y TRANSFORMACIÓN DE LOS DATOS**\n",
    "\n",
    "Este notebook aplica las transformaciones de limpieza derivadas del EDA y realiza validaciones básicas para asegurar consistencia y calidad de los datos antes del análisis.\n",
    "\n",
    "**Principios**\n",
    "- Transformar y exportar el dataset limpio a `data/processed/`.\n",
    "- Documentar cada transformación y su motivación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daea87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0e9ce",
   "metadata": {},
   "source": [
    "#### **1. CARGA E INTEGRACIÓN DE LOS DATASETS**\n",
    "\n",
    "- En esta sección se cargan los datasets originales y se integran en un único DataFrame de trabajo mediante la función `lectura_ficheros`.\n",
    "- Esta función automatiza el proceso de integración, detectando la columna común entre ambos datasets y analizando su correspondencia para determinar el tipo de unión más adecuado.\n",
    "- Este enfoque garantiza un proceso robusto y reutilizable, evitando depender de nombres de columnas específicos.\n",
    "- El DataFrame resultante se utilizará como base para las siguientes fases de limpieza y validación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3185f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_ficheros(path_df1, path_df2):\n",
    "    \"\"\"\n",
    "    Carga dos datasets, detecta automáticamente la columna común entre ambos,\n",
    "    analiza el grado de correspondencia de dicha clave y realiza la unión recomendada.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    path_df1 : str\n",
    "        Ruta al primer fichero CSV.\n",
    "\n",
    "    path_df2 : str\n",
    "        Ruta al segundo fichero CSV.\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame resultante de la unión de ambos datasets mediante la clave común detectada.\n",
    "\n",
    "    Qué hace\n",
    "    --------\n",
    "    1. Carga ambos datasets desde las rutas especificadas.\n",
    "    2. Detecta automáticamente la(s) columna(s) común(es).\n",
    "    3. Selecciona la primera columna común como clave de unión.\n",
    "    4. Calcula el porcentaje de correspondencia de dicha clave entre ambos datasets.\n",
    "    5. Determina el tipo de unión recomendado (inner, left, right u outer).\n",
    "    6. Realiza el merge utilizando la clave y el tipo de unión recomendado.\n",
    "    7. Muestra información básica del resultado.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    Esta función permite automatizar el proceso de unión sin depender de un nombre de columna\n",
    "    específico, haciendo el código reutilizable en distintos datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"LECTURA DE FICHEROS\")\n",
    "\n",
    "    # Carga de datos\n",
    "    df1 = pd.read_csv(path_df1)\n",
    "    df2 = pd.read_csv(path_df2)\n",
    "\n",
    "    print(f\"Dataset 1: {df1.shape[0]} filas × {df1.shape[1]} columnas\")\n",
    "    print(f\"Dataset 2: {df2.shape[0]} filas × {df2.shape[1]} columnas\")\n",
    "\n",
    "    # Detectar columnas comunes\n",
    "    columnas_comunes = list(set(df1.columns).intersection(df2.columns))\n",
    "\n",
    "    if not columnas_comunes:\n",
    "        raise ValueError(\"ERROR: No se encontraron columnas comunes entre los datasets.\")\n",
    "\n",
    "    print(\"\\nColumnas comunes detectadas:\")\n",
    "    for col in columnas_comunes:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "    # Seleccionar la primera columna común como clave\n",
    "    key = columnas_comunes[0]\n",
    "    print(f\"\\nClave seleccionada: {key}\")\n",
    "\n",
    "    # ==================================================\n",
    "    # ANÁLISIS DE CORRESPONDENCIA\n",
    "    # ==================================================\n",
    "\n",
    "    match_df1 = df1[key].isin(df2[key]).mean() * 100\n",
    "    match_df2 = df2[key].isin(df1[key]).mean() * 100\n",
    "\n",
    "    print(\"\\nANÁLISIS DE CORRESPONDENCIA\")\n",
    "    print(f\"% claves de df1 presentes en df2: {match_df1:.2f}%\")\n",
    "    print(f\"% claves de df2 presentes en df1: {match_df2:.2f}%\")\n",
    "\n",
    "    # Determinar join recomendado\n",
    "    if match_df1 == 100 and match_df2 == 100:\n",
    "        join_type = \"inner\"\n",
    "        print(\"Correspondencia completa → recomendado: INNER JOIN\")\n",
    "\n",
    "    elif match_df1 < 100 and match_df2 == 100:\n",
    "        join_type = \"left\"\n",
    "        print(\"df1 tiene claves sin correspondencia → recomendado: LEFT JOIN\")\n",
    "\n",
    "    elif match_df1 == 100 and match_df2 < 100:\n",
    "        join_type = \"right\"\n",
    "        print(\"df2 tiene claves sin correspondencia → recomendado: RIGHT JOIN\")\n",
    "\n",
    "    else:\n",
    "        join_type = \"outer\"\n",
    "        print(\"Correspondencia parcial → recomendado: OUTER JOIN\")\n",
    "\n",
    "    # ==================================================\n",
    "    # MERGE\n",
    "    # ==================================================\n",
    "\n",
    "    df = df1.merge(df2, on=key, how=join_type)\n",
    "\n",
    "    print(f\"\\nRESULTADO DEL MERGE ({join_type.upper()})\")\n",
    "    print(f\"Shape final: {df.shape[0]} filas × {df.shape[1]} columnas\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cdfad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LECTURA DE FICHEROS\n",
      "Dataset 1: 405624 filas × 10 columnas\n",
      "Dataset 2: 16737 filas × 16 columnas\n",
      "\n",
      "Columnas comunes detectadas:\n",
      "  - Loyalty Number\n",
      "\n",
      "Clave seleccionada: Loyalty Number\n",
      "\n",
      "ANÁLISIS DE CORRESPONDENCIA\n",
      "% claves de df1 presentes en df2: 100.00%\n",
      "% claves de df2 presentes en df1: 100.00%\n",
      "Correspondencia completa → recomendado: INNER JOIN\n",
      "\n",
      "RESULTADO DEL MERGE (INNER)\n",
      "Shape final: 405624 filas × 25 columnas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loyalty Number</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Flights Booked</th>\n",
       "      <th>Flights with Companions</th>\n",
       "      <th>Total Flights</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Points Accumulated</th>\n",
       "      <th>Points Redeemed</th>\n",
       "      <th>Dollar Cost Points Redeemed</th>\n",
       "      <th>Country</th>\n",
       "      <th>Province</th>\n",
       "      <th>City</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>CLV</th>\n",
       "      <th>Enrollment Type</th>\n",
       "      <th>Enrollment Year</th>\n",
       "      <th>Enrollment Month</th>\n",
       "      <th>Cancellation Year</th>\n",
       "      <th>Cancellation Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.20</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100102</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2030</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>M1R 4K3</td>\n",
       "      <td>Male</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Nova</td>\n",
       "      <td>2887.74</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100140</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1200</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Dawson Creek</td>\n",
       "      <td>U5I 4F1</td>\n",
       "      <td>Female</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Nova</td>\n",
       "      <td>2838.07</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100214</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>V5R 1W3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>63253.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>4170.57</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100272</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>P1L 8X8</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>91163.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>6622.05</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loyalty Number  Year  Month  Flights Booked  Flights with Companions  \\\n",
       "0          100018  2017      1               3                        0   \n",
       "1          100102  2017      1              10                        4   \n",
       "2          100140  2017      1               6                        0   \n",
       "3          100214  2017      1               0                        0   \n",
       "4          100272  2017      1               0                        0   \n",
       "\n",
       "   Total Flights  Distance  Points Accumulated  Points Redeemed  \\\n",
       "0              3      1521               152.0                0   \n",
       "1             14      2030               203.0                0   \n",
       "2              6      1200               120.0                0   \n",
       "3              0         0                 0.0                0   \n",
       "4              0         0                 0.0                0   \n",
       "\n",
       "   Dollar Cost Points Redeemed Country          Province          City  \\\n",
       "0                            0  Canada           Alberta      Edmonton   \n",
       "1                            0  Canada           Ontario       Toronto   \n",
       "2                            0  Canada  British Columbia  Dawson Creek   \n",
       "3                            0  Canada  British Columbia     Vancouver   \n",
       "4                            0  Canada           Ontario       Toronto   \n",
       "\n",
       "  Postal Code  Gender Education   Salary Marital Status Loyalty Card      CLV  \\\n",
       "0     T9G 1W3  Female  Bachelor  92552.0        Married       Aurora  7919.20   \n",
       "1     M1R 4K3    Male   College      NaN         Single         Nova  2887.74   \n",
       "2     U5I 4F1  Female   College      NaN       Divorced         Nova  2838.07   \n",
       "3     V5R 1W3    Male  Bachelor  63253.0        Married         Star  4170.57   \n",
       "4     P1L 8X8  Female  Bachelor  91163.0       Divorced         Star  6622.05   \n",
       "\n",
       "  Enrollment Type  Enrollment Year  Enrollment Month  Cancellation Year  \\\n",
       "0        Standard             2016                 8                NaN   \n",
       "1        Standard             2013                 3                NaN   \n",
       "2        Standard             2016                 7                NaN   \n",
       "3        Standard             2015                 8                NaN   \n",
       "4        Standard             2014                 1                NaN   \n",
       "\n",
       "   Cancellation Month  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df1 = \"../data/raw/Customer Flight Activity.csv\"\n",
    "path_df2 = \"../data/raw/Customer Loyalty History.csv\"\n",
    "df = lectura_ficheros(path_df1, path_df2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ebc176",
   "metadata": {},
   "source": [
    "#### **2. HOMOGENEIZACIÓN Y RENOMBRADO DE COLUMNAS**\n",
    "\n",
    "- En esta sección se estandarizan los nombres de las columnas para garantizar consistencia y facilitar su uso en las fases posteriores del análisis.\n",
    "- Primero, se normalizan los nombres al formato `snake_case`, eliminando espacios y caracteres especiales.\n",
    "- Posteriormente, se renombran aquellas variables con nomenclatura ambigua para mejorar su claridad semántica (por ejemplo, `year` y `month` se renombran a `flight_year` y `flight_month`).\n",
    "- Este proceso mejora la legibilidad del dataset y facilita su manipulación en el flujo de limpieza y análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "920033b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_nombres_columnas(lista_columnas, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Normaliza los nombres de las columnas a formato snake_case.\n",
    "\n",
    "    El proceso incluye:\n",
    "    - Eliminar espacios al inicio y al final\n",
    "    - Reemplazar espacios intermedios y caracteres especiales por guiones bajos\n",
    "    - Convertir de CamelCase/PascalCase a snake_case\n",
    "    - Convertir todo a minúsculas\n",
    "    - Eliminar guiones bajos duplicados\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    lista_columnas : list\n",
    "        Lista con los nombres originales de las columnas.\n",
    "\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, muestra el resumen de cambios realizados.\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    list\n",
    "        Lista con los nombres normalizados en formato snake_case.\n",
    "\n",
    "    Ejemplo\n",
    "    -------\n",
    "    >>> normalizar_nombres_columnas(['Loyalty Number', 'CLV'])\n",
    "    ['loyalty_number', 'clv']\n",
    "    \"\"\"\n",
    "       \n",
    "    nombres_normalizados = []\n",
    "\n",
    "    for nombre in lista_columnas:\n",
    "\n",
    "        # 1. eliminar espacios extremos\n",
    "        limpia = nombre.strip()\n",
    "\n",
    "        # 2. reemplazar espacios y caracteres especiales por _\n",
    "        limpia = re.sub(r'[^0-9a-zA-Z]+', '_', limpia)\n",
    "\n",
    "        # 3. convertir a minúsculas\n",
    "        limpia = limpia.lower()\n",
    "\n",
    "        # 4. eliminar _ duplicados\n",
    "        limpia = re.sub(r'_+', '_', limpia)\n",
    "\n",
    "        # 5. eliminar _ inicial o final\n",
    "        limpia = limpia.strip('_')\n",
    "\n",
    "        nombres_normalizados.append(limpia)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"Normalización de nombres de columnas finalizada.\")\n",
    "        print(f\"Total columnas procesadas: {len(nombres_normalizados)}\")\n",
    "        print(\"Resumen de cambios:\")\n",
    "        for orig, nuevo in zip(lista_columnas, nombres_normalizados):\n",
    "            print(f\"  '{orig}' → '{nuevo}'\")\n",
    "\n",
    "    return nombres_normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6cdfe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalización de nombres de columnas finalizada.\n",
      "Total columnas procesadas: 25\n",
      "Resumen de cambios:\n",
      "  'Loyalty Number' → 'loyalty_number'\n",
      "  'Year' → 'year'\n",
      "  'Month' → 'month'\n",
      "  'Flights Booked' → 'flights_booked'\n",
      "  'Flights with Companions' → 'flights_with_companions'\n",
      "  'Total Flights' → 'total_flights'\n",
      "  'Distance' → 'distance'\n",
      "  'Points Accumulated' → 'points_accumulated'\n",
      "  'Points Redeemed' → 'points_redeemed'\n",
      "  'Dollar Cost Points Redeemed' → 'dollar_cost_points_redeemed'\n",
      "  'Country' → 'country'\n",
      "  'Province' → 'province'\n",
      "  'City' → 'city'\n",
      "  'Postal Code' → 'postal_code'\n",
      "  'Gender' → 'gender'\n",
      "  'Education' → 'education'\n",
      "  'Salary' → 'salary'\n",
      "  'Marital Status' → 'marital_status'\n",
      "  'Loyalty Card' → 'loyalty_card'\n",
      "  'CLV' → 'clv'\n",
      "  'Enrollment Type' → 'enrollment_type'\n",
      "  'Enrollment Year' → 'enrollment_year'\n",
      "  'Enrollment Month' → 'enrollment_month'\n",
      "  'Cancellation Year' → 'cancellation_year'\n",
      "  'Cancellation Month' → 'cancellation_month'\n"
     ]
    }
   ],
   "source": [
    "df.columns = normalizar_nombres_columnas(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c2da6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renombrar_columnas_semanticas(df, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Renombra columnas para mejorar la claridad semántica y eliminar ambigüedades.\n",
    "\n",
    "    Este paso se aplica después de la normalización a snake_case y permite\n",
    "    asignar nombres más descriptivos a variables cuyo significado no es\n",
    "    evidente o puede generar confusión.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame cuyas columnas serán renombradas.\n",
    "\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, muestra el resumen de los cambios realizados.\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con las columnas renombradas.\n",
    "\n",
    "    Cambios aplicados\n",
    "    -----------------\n",
    "    - year → flight_year\n",
    "    - month → flight_month\n",
    "    - clv → customer_lifetime_value\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    Este paso mejora la interpretabilidad del dataset y evita ambigüedades,\n",
    "    especialmente cuando existen múltiples variables relacionadas con fechas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se define un diccionario de mapeo donde la clave representa el nombre original de la columna\n",
    "    # y el valor el nuevo nombre asignado, con el objetivo de mejorar la claridad semántica.\n",
    "    rename_map = {\n",
    "        \"year\": \"flight_year\",\n",
    "        \"month\": \"flight_month\",\n",
    "        \"clv\": \"customer_lifetime_value\"\n",
    "    }\n",
    "\n",
    "    # Mediante el método .rename(), se aplican estos cambios al DataFrame, alineando la nomenclatura\n",
    "    # con el estándar definido previamente en las funciones de homogeneización de columnas.\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"Renombrado semántico de columnas aplicado:\")\n",
    "        for original, nuevo in rename_map.items():\n",
    "            if original in df.columns or nuevo in df.columns:\n",
    "                print(f\"  '{original}' → '{nuevo}'\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9a444bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renombrado semántico de columnas aplicado:\n",
      "  'year' → 'flight_year'\n",
      "  'month' → 'flight_month'\n",
      "  'clv' → 'customer_lifetime_value'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loyalty_number</th>\n",
       "      <th>flight_year</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>flights_booked</th>\n",
       "      <th>flights_with_companions</th>\n",
       "      <th>total_flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>points_accumulated</th>\n",
       "      <th>points_redeemed</th>\n",
       "      <th>dollar_cost_points_redeemed</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>salary</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>loyalty_card</th>\n",
       "      <th>customer_lifetime_value</th>\n",
       "      <th>enrollment_type</th>\n",
       "      <th>enrollment_year</th>\n",
       "      <th>enrollment_month</th>\n",
       "      <th>cancellation_year</th>\n",
       "      <th>cancellation_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.20</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100102</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2030</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>M1R 4K3</td>\n",
       "      <td>Male</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Nova</td>\n",
       "      <td>2887.74</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100140</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1200</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Dawson Creek</td>\n",
       "      <td>U5I 4F1</td>\n",
       "      <td>Female</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Nova</td>\n",
       "      <td>2838.07</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100214</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>V5R 1W3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>63253.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>4170.57</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100272</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>P1L 8X8</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>91163.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>6622.05</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loyalty_number  flight_year  flight_month  flights_booked  \\\n",
       "0          100018         2017             1               3   \n",
       "1          100102         2017             1              10   \n",
       "2          100140         2017             1               6   \n",
       "3          100214         2017             1               0   \n",
       "4          100272         2017             1               0   \n",
       "\n",
       "   flights_with_companions  total_flights  distance  points_accumulated  \\\n",
       "0                        0              3      1521               152.0   \n",
       "1                        4             14      2030               203.0   \n",
       "2                        0              6      1200               120.0   \n",
       "3                        0              0         0                 0.0   \n",
       "4                        0              0         0                 0.0   \n",
       "\n",
       "   points_redeemed  dollar_cost_points_redeemed country          province  \\\n",
       "0                0                            0  Canada           Alberta   \n",
       "1                0                            0  Canada           Ontario   \n",
       "2                0                            0  Canada  British Columbia   \n",
       "3                0                            0  Canada  British Columbia   \n",
       "4                0                            0  Canada           Ontario   \n",
       "\n",
       "           city postal_code  gender education   salary marital_status  \\\n",
       "0      Edmonton     T9G 1W3  Female  Bachelor  92552.0        Married   \n",
       "1       Toronto     M1R 4K3    Male   College      NaN         Single   \n",
       "2  Dawson Creek     U5I 4F1  Female   College      NaN       Divorced   \n",
       "3     Vancouver     V5R 1W3    Male  Bachelor  63253.0        Married   \n",
       "4       Toronto     P1L 8X8  Female  Bachelor  91163.0       Divorced   \n",
       "\n",
       "  loyalty_card  customer_lifetime_value enrollment_type  enrollment_year  \\\n",
       "0       Aurora                  7919.20        Standard             2016   \n",
       "1         Nova                  2887.74        Standard             2013   \n",
       "2         Nova                  2838.07        Standard             2016   \n",
       "3         Star                  4170.57        Standard             2015   \n",
       "4         Star                  6622.05        Standard             2014   \n",
       "\n",
       "   enrollment_month  cancellation_year  cancellation_month  \n",
       "0                 8                NaN                 NaN  \n",
       "1                 3                NaN                 NaN  \n",
       "2                 7                NaN                 NaN  \n",
       "3                 8                NaN                 NaN  \n",
       "4                 1                NaN                 NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = renombrar_columnas_semanticas(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e73b1",
   "metadata": {},
   "source": [
    "#### **3. ELIMINACIÓN DE FILAS DUPLICADAS**\n",
    "\n",
    "- En esta sección se identifican y eliminan filas completamente duplicadas del dataset.\n",
    "- Se consideran duplicados aquellos registros que presentan valores idénticos en todas las columnas.\n",
    "- La eliminación de estos registros evita redundancias y garantiza la integridad del conjunto de datos.\n",
    "- Este proceso no afecta a registros válidos derivados de la estructura temporal del dataset, donde un mismo cliente puede aparecer en múltiples periodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3d32ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_filas_duplicadas(df, keep='first'):\n",
    "    \"\"\"\n",
    "    Elimina filas completamente duplicadas del DataFrame.\n",
    "\n",
    "    Se consideran duplicados aquellas filas que tienen valores idénticos en\n",
    "    todas las columnas.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame a procesar.\n",
    "\n",
    "    keep : {'first', 'last', False}, default='first'\n",
    "        Determina qué ocurrencia conservar:\n",
    "        - 'first' : conserva la primera aparición\n",
    "        - 'last'  : conserva la última aparición\n",
    "        - False   : elimina todas las ocurrencias duplicadas\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame sin filas duplicadas.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ELIMINACIÓN DE FILAS DUPLICADAS\")\n",
    "    # Crear copia de seguridad\n",
    "    df = df.copy()\n",
    "\n",
    "    filas_originales = df.shape[0]\n",
    "\n",
    "    #Elimina duplicados\n",
    "    df.drop_duplicates(keep=keep, inplace=True)\n",
    "\n",
    "    filas_tras_depuracion = df.shape[0]\n",
    "    filas_eliminadas = filas_originales - filas_tras_depuracion\n",
    "\n",
    "    print(f\"Filas iniciales: {filas_originales}\")\n",
    "    print(f\"Filas eliminadas: {filas_eliminadas}\")\n",
    "    print(f\"Filas finales: {filas_tras_depuracion}\")\n",
    "\n",
    "    if filas_eliminadas == 0:\n",
    "        print(\"No se detectaron duplicados exactos.\")\n",
    "    else:\n",
    "        print(\"Duplicados eliminados correctamente.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00ccca9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINACIÓN DE FILAS DUPLICADAS\n",
      "Filas iniciales: 405624\n",
      "Filas eliminadas: 1864\n",
      "Filas finales: 403760\n",
      "Duplicados eliminados correctamente.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loyalty_number</th>\n",
       "      <th>flight_year</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>flights_booked</th>\n",
       "      <th>flights_with_companions</th>\n",
       "      <th>total_flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>points_accumulated</th>\n",
       "      <th>points_redeemed</th>\n",
       "      <th>dollar_cost_points_redeemed</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>salary</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>loyalty_card</th>\n",
       "      <th>customer_lifetime_value</th>\n",
       "      <th>enrollment_type</th>\n",
       "      <th>enrollment_year</th>\n",
       "      <th>enrollment_month</th>\n",
       "      <th>cancellation_year</th>\n",
       "      <th>cancellation_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.20</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100102</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2030</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>M1R 4K3</td>\n",
       "      <td>Male</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Nova</td>\n",
       "      <td>2887.74</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100140</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1200</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Dawson Creek</td>\n",
       "      <td>U5I 4F1</td>\n",
       "      <td>Female</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Nova</td>\n",
       "      <td>2838.07</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100214</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>V5R 1W3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>63253.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>4170.57</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100272</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>P1L 8X8</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>91163.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>6622.05</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loyalty_number  flight_year  flight_month  flights_booked  \\\n",
       "0          100018         2017             1               3   \n",
       "1          100102         2017             1              10   \n",
       "2          100140         2017             1               6   \n",
       "3          100214         2017             1               0   \n",
       "4          100272         2017             1               0   \n",
       "\n",
       "   flights_with_companions  total_flights  distance  points_accumulated  \\\n",
       "0                        0              3      1521               152.0   \n",
       "1                        4             14      2030               203.0   \n",
       "2                        0              6      1200               120.0   \n",
       "3                        0              0         0                 0.0   \n",
       "4                        0              0         0                 0.0   \n",
       "\n",
       "   points_redeemed  dollar_cost_points_redeemed country          province  \\\n",
       "0                0                            0  Canada           Alberta   \n",
       "1                0                            0  Canada           Ontario   \n",
       "2                0                            0  Canada  British Columbia   \n",
       "3                0                            0  Canada  British Columbia   \n",
       "4                0                            0  Canada           Ontario   \n",
       "\n",
       "           city postal_code  gender education   salary marital_status  \\\n",
       "0      Edmonton     T9G 1W3  Female  Bachelor  92552.0        Married   \n",
       "1       Toronto     M1R 4K3    Male   College      NaN         Single   \n",
       "2  Dawson Creek     U5I 4F1  Female   College      NaN       Divorced   \n",
       "3     Vancouver     V5R 1W3    Male  Bachelor  63253.0        Married   \n",
       "4       Toronto     P1L 8X8  Female  Bachelor  91163.0       Divorced   \n",
       "\n",
       "  loyalty_card  customer_lifetime_value enrollment_type  enrollment_year  \\\n",
       "0       Aurora                  7919.20        Standard             2016   \n",
       "1         Nova                  2887.74        Standard             2013   \n",
       "2         Nova                  2838.07        Standard             2016   \n",
       "3         Star                  4170.57        Standard             2015   \n",
       "4         Star                  6622.05        Standard             2014   \n",
       "\n",
       "   enrollment_month  cancellation_year  cancellation_month  \n",
       "0                 8                NaN                 NaN  \n",
       "1                 3                NaN                 NaN  \n",
       "2                 7                NaN                 NaN  \n",
       "3                 8                NaN                 NaN  \n",
       "4                 1                NaN                 NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = eliminar_filas_duplicadas(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7492c5",
   "metadata": {},
   "source": [
    "#### **4. CORRECCIÓN DE TIPOS DE DATOS**\n",
    "\n",
    "- En esta sección se corrigen los tipos de datos de aquellas variables cuyo tipo original no es el más adecuado según su naturaleza.\n",
    "- Las variables discretas con valores nulos se convierten a tipo entero nullable (`Int64`), mientras que las variables continuas o monetarias se convierten a tipo `float`.\n",
    "- Esta corrección garantiza una representación coherente de los datos y evita problemas en fases posteriores de análisis.\n",
    "- El proceso se implementa mediante un diccionario de mapeo columna → tipo, facilitando su reutilización y mantenimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5884d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_tipos_datos(df, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Corrige los tipos de datos de las columnas de un DataFrame según su naturaleza.\n",
    "\n",
    "    Esta función permite convertir variables a su tipo más adecuado utilizando\n",
    "    un diccionario de mapeo columna → tipo. Es especialmente útil para:\n",
    "\n",
    "    - Convertir variables discretas con nulos a entero nullable (Int64)\n",
    "    - Convertir variables discretas sin nulos a entero (int64)\n",
    "    - Convertir variables continuas o monetarias a float (float64)\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame cuyas columnas serán convertidas.\n",
    "\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, muestra el resumen de los cambios realizados.\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con los tipos de datos corregidos.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    Solo se aplican conversiones a columnas existentes en el DataFrame,\n",
    "    permitiendo que la función sea reutilizable en distintos datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Diccionario columna → tipo destino\n",
    "    dtype_map = {\n",
    "        # Variables discretas con nulos → entero nullable\n",
    "        \"cancellation_year\": \"Int64\",\n",
    "        \"cancellation_month\": \"Int64\",\n",
    "        # Variables discretas sin nulos → entero\n",
    "        \"points_accumulated\": \"int64\",\n",
    "        # Variables continuas / monetarias → float\n",
    "        \"distance\": \"float64\",\n",
    "        \"dollar_cost_points_redeemed\": \"float64\"\n",
    "    }\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"CORRECCIÓN DE TIPOS DE DATOS\")\n",
    "        print(\"Columnas convertidas:\")\n",
    "\n",
    "    # Aplicar conversiones solo si la columna existe\n",
    "    for col, dtype in dtype_map.items():\n",
    "        if col in df.columns:\n",
    "            dtype_original = df[col].dtype\n",
    "            df[col] = df[col].astype(dtype)\n",
    "            \n",
    "            if mostrar_resumen:\n",
    "                print(f\"  {col}: {dtype_original} → {dtype}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af3f1c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECCIÓN DE TIPOS DE DATOS\n",
      "Columnas convertidas:\n",
      "  cancellation_year: float64 → Int64\n",
      "  cancellation_month: float64 → Int64\n",
      "  points_accumulated: float64 → int64\n",
      "  distance: int64 → float64\n",
      "  dollar_cost_points_redeemed: int64 → float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loyalty_number                   int64\n",
       "flight_year                      int64\n",
       "flight_month                     int64\n",
       "flights_booked                   int64\n",
       "flights_with_companions          int64\n",
       "total_flights                    int64\n",
       "distance                       float64\n",
       "points_accumulated               int64\n",
       "points_redeemed                  int64\n",
       "dollar_cost_points_redeemed    float64\n",
       "country                         object\n",
       "province                        object\n",
       "city                            object\n",
       "postal_code                     object\n",
       "gender                          object\n",
       "education                       object\n",
       "salary                         float64\n",
       "marital_status                  object\n",
       "loyalty_card                    object\n",
       "customer_lifetime_value        float64\n",
       "enrollment_type                 object\n",
       "enrollment_year                  int64\n",
       "enrollment_month                 int64\n",
       "cancellation_year                Int64\n",
       "cancellation_month               Int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = corregir_tipos_datos(df)\n",
    "\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958b54a",
   "metadata": {},
   "source": [
    "#### **5. TRATAMIENTO DE VALORES NEGATIVOS**\n",
    "\n",
    "- En esta sección se identifican y corrigen valores negativos en variables cuya naturaleza no admite este tipo de valores.\n",
    "- Los valores negativos se consideran inconsistencias derivadas de errores de calidad de datos, ya que no representan situaciones válidas desde el punto de vista analítico.\n",
    "- Estos valores son convertidos a valores nulos (`NaN`) para permitir su tratamiento posterior mediante técnicas de imputación, evitando eliminar registros completos y preservando el volumen de información disponible.\n",
    "- Este tratamiento se aplica específicamente sobre la variable `salary`, que representa el ingreso anual estimado del cliente y no puede tomar valores negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "597f70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_negativos_a_nulos(df, columna, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Convierte valores negativos de una columna numérica en valores nulos (NaN).\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame a procesar.\n",
    "\n",
    "    columna : str\n",
    "        Nombre de la columna donde se corregirán los valores negativos.\n",
    "\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, muestra el número de valores corregidos.\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con los valores negativos convertidos a NaN.\n",
    "\n",
    "    Qué hace\n",
    "    --------\n",
    "    - Identifica valores negativos en la columna especificada.\n",
    "    - Sustituye dichos valores por NaN, al considerarse inconsistentes con la\n",
    "      naturaleza de la variable.\n",
    "    - Muestra un resumen del número de valores corregidos (opcional).\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calcular el número de registros con valores negativos en la columna especificada,\n",
    "    # lo que permite cuantificar el alcance de la corrección aplicada\n",
    "    n_negativos = (df[columna] < 0).sum()\n",
    "    \n",
    "    # Reemplazar los valores negativos por NaN, ya que representan valores inválidos\n",
    "    # según la naturaleza de la variable y deben ser tratados como datos faltantes\n",
    "    df.loc[df[columna] < 0, columna] = np.nan\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(f\"{columna}: {n_negativos} valores negativos convertidos a NaN\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c71fc35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary: 480 valores negativos convertidos a NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    301020.000000\n",
       "mean      79441.628829\n",
       "std       34704.340158\n",
       "min       15609.000000\n",
       "25%       59278.000000\n",
       "50%       73523.000000\n",
       "75%       88626.000000\n",
       "max      407228.000000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conversión de valores negativos a nulos en la variable salary\n",
    "df = convertir_negativos_a_nulos(df, \"salary\")\n",
    "\n",
    "# Verificar resultado\n",
    "display(df[\"salary\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbc302",
   "metadata": {},
   "source": [
    "#### **6. TRATAMIENTO DE VALORES NULOS**\n",
    "\n",
    "- En esta sección se analiza y trata la presencia de valores nulos, aplicando distintas estrategias en función de la naturaleza y significado de cada variable.\n",
    "- A partir del análisis exploratorio (EDA), se identificaron dos casuísticas diferenciadas que requieren tratamientos distintos.\n",
    "\n",
    "**Variables que requieren imputación**\n",
    "\n",
    "- La variable `salary` presenta valores nulos que corresponden a información faltante, no a una condición real del cliente.\n",
    "- Dado que el salario es una variable continua con relevancia analítica, estos valores se imputan utilizando la mediana calculada por grupos de clientes con características similares (`education` y `loyalty_card`).\n",
    "- Este enfoque permite preservar la estructura socioeconómica del dataset y evitar sesgos derivados de imputaciones globales.\n",
    "\n",
    "**Variables cuyos valores nulos representan una condición válida**\n",
    "\n",
    "- Las variables `cancellation_year` y `cancellation_month` presentan un alto porcentaje de valores nulos.\n",
    "- Sin embargo, estos valores nulos no representan errores ni información faltante, sino que indican que el cliente no ha cancelado su membresía en el programa de fidelización.\n",
    "- Por este motivo, estos valores se mantienen como nulos, ya que constituyen información válida y relevante desde el punto de vista analítico.\n",
    "- Se crea la variable `customer_status` para identificar si el cliente se encuentra activo o ha cancelado su membresía, facilitando el análisis del comportamiento y la segmentación entre clientes activos y cancelados.\n",
    "\n",
    "- Este tratamiento diferenciado garantiza la coherencia semántica de los datos y asegura una preparación adecuada del dataset para fases posteriores de análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fd867c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_salary_por_grupos(df, columna=\"salary\", mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Imputa valores nulos en una variable continua utilizando la mediana\n",
    "    calculada por grupos de variables estructurales relacionadas.\n",
    "\n",
    "    En este caso, la imputación se realiza de forma jerárquica:\n",
    "    Mediana por grupo de education y loyalty_card\n",
    "\n",
    "    Este enfoque permite imputar valores de forma más realista, preservando\n",
    "    las diferencias salariales entre segmentos de clientes y evitando el uso\n",
    "    exclusivo de la mediana global.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame que contiene la variable a imputar.\n",
    "\n",
    "    columna : str, default=\"salary\"\n",
    "        Nombre de la columna sobre la que se realizará la imputación.\n",
    "\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, muestra un resumen del proceso de imputación.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con los valores imputados.\n",
    "    \"\"\"\n",
    "     \n",
    "    df = df.copy()\n",
    "\n",
    "    nulos_antes = df[columna].isnull().sum()\n",
    "\n",
    "    # 1) Mediana por grupos (si el grupo tiene mediana NaN, no imputa)\n",
    "    mediana_grupo = df.groupby([\"education\", \"loyalty_card\"])[columna].transform(\"median\")\n",
    "    df[columna] = df[columna].fillna(mediana_grupo)\n",
    "\n",
    "    # 2) Fallback por education (para los grupos que no se hayan podido imputar en el paso anterior)\n",
    "    mediana_edu = df.groupby(\"education\")[columna].transform(\"median\")\n",
    "    df[columna] = df[columna].fillna(mediana_edu)\n",
    "\n",
    "    # 3) Fallback final: mediana global (para los nulos restantes)\n",
    "    mediana_global = df[columna].median()\n",
    "    df[columna] = df[columna].fillna(mediana_global)\n",
    "\n",
    "    nulos_despues = df[columna].isnull().sum()\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"IMPUTACIÓN DE SALARY FINALIZADA\")\n",
    "        print(f\"Valores nulos antes: {nulos_antes:,}\")\n",
    "        print(f\"Valores imputados: {nulos_antes - nulos_despues:,}\")\n",
    "        print(f\"Valores nulos restantes: {nulos_despues:,}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09217dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPUTACIÓN DE SALARY FINALIZADA\n",
      "Valores nulos antes: 102,740\n",
      "Valores imputados: 102,740\n",
      "Valores nulos restantes: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    403760.000000\n",
       "mean      77922.166857\n",
       "std       30078.197775\n",
       "min       15609.000000\n",
       "25%       64001.000000\n",
       "50%       73479.000000\n",
       "75%       82940.000000\n",
       "max      407228.000000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = imputar_salary_por_grupos(df)\n",
    "df['salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74edf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_estado_cliente(valor):\n",
    "    \"\"\"\n",
    "    Clasifica el estado del cliente en función del año de cancelación.\n",
    "\n",
    "    Devuelve \"Active\" si el cliente no presenta año de cancelación (NaN),\n",
    "    y \"Cancelled\" si el cliente ha cancelado su membresía.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(valor):\n",
    "        return \"Active\"\n",
    "    else:\n",
    "        return \"Cancelled\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c31ee876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"customer_status\"] = df[\"cancellation_year\"].apply(clasificar_estado_cliente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e022c5",
   "metadata": {},
   "source": [
    "#### **7. LIMPIEZA DE VARIABLES CATEGÓRICAS**\n",
    "\n",
    "- En esta sección se estandariza el formato de las variables categóricas.\n",
    "- Se eliminan espacios al inicio y al final de los valores y se aplica un formato homogéneo de capitalización.\n",
    "- Este proceso garantiza la consistencia de las categorías y evita la duplicación de valores equivalentes con distinta representación.\n",
    "- Aunque durante el EDA no se detectaron inconsistencias en el formato de las variables categóricas, se aplica este proceso como medida preventiva para garantizar la consistencia del dataset y asegurar un flujo de limpieza automatizado y robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b385809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_categoricas(df, columnas=None):\n",
    "    \"\"\"\n",
    "    Limpia variables categóricas eliminando espacios y unificando el formato del texto.\n",
    "\n",
    "    Aplica .str.strip().str.title() para garantizar consistencia en las categorías.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame a procesar.\n",
    "\n",
    "    columnas : list, default=None\n",
    "        Columnas a limpiar. Si es None, se aplicará a todas las columnas categóricas.\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con las variables categóricas limpias.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Si no se especifican columnas, detectar todas las categóricas\n",
    "    if columnas is None:\n",
    "        columnas = df.select_dtypes(include=\"O\").columns\n",
    "\n",
    "    # Aplicar limpieza básica\n",
    "    for col in columnas:\n",
    "        df[col] = df[col].str.strip().str.title()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faad8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = limpiar_categoricas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22818368",
   "metadata": {},
   "source": [
    "#### **8. REVISIÓN DE INCOHERENCIAS LÓGICAS**\n",
    "\n",
    "- En esta sección se validan las relaciones lógicas entre variables relacionadas con la actividad de vuelos.\n",
    "- Se comprueba la coherencia entre el número de vuelos, la distancia recorrida y los puntos acumulados y redimidos.\n",
    "- Esta validación permite detectar posibles errores derivados de inconsistencias en el registro de la información.\n",
    "- No se detectaron incoherencias significativas, lo que confirma la consistencia estructural del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e236af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revisar_incoherencias_vuelos(df):\n",
    "    \"\"\"\n",
    "    Detecta posibles incoherencias lógicas en las variables relacionadas.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    incoherencias = {}\n",
    "\n",
    "    incoherencias[\"booked > total\"] = (df[\"flights_booked\"] > df[\"total_flights\"]).sum()\n",
    "\n",
    "    incoherencias[\"companions > total\"] = (\n",
    "        df[\"flights_with_companions\"] > df[\"total_flights\"]\n",
    "    ).sum()\n",
    "\n",
    "    incoherencias[\"distance > 0 pero total_flights = 0\"] = (\n",
    "        (df[\"total_flights\"] == 0) & (df[\"distance\"] > 0)\n",
    "    ).sum()\n",
    "\n",
    "    incoherencias[\"points_accumulated > 0 pero total_flights = 0\"] = (\n",
    "        (df[\"total_flights\"] == 0) & (df[\"points_accumulated\"] > 0)\n",
    "    ).sum()\n",
    "\n",
    "    print(\"REVISIÓN DE INCOHERENCIAS LÓGICAS\")\n",
    "    for k, v in incoherencias.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    return incoherencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f537733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVISIÓN DE INCOHERENCIAS LÓGICAS\n",
      "booked > total: 0\n",
      "companions > total: 0\n",
      "distance > 0 pero total_flights = 0: 0\n",
      "points_accumulated > 0 pero total_flights = 0: 0\n"
     ]
    }
   ],
   "source": [
    "revisar_incoherencias_vuelos(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a91dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 403760 entries, 0 to 405623\n",
      "Data columns (total 26 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   loyalty_number               403760 non-null  int64  \n",
      " 1   flight_year                  403760 non-null  int64  \n",
      " 2   flight_month                 403760 non-null  int64  \n",
      " 3   flights_booked               403760 non-null  int64  \n",
      " 4   flights_with_companions      403760 non-null  int64  \n",
      " 5   total_flights                403760 non-null  int64  \n",
      " 6   distance                     403760 non-null  float64\n",
      " 7   points_accumulated           403760 non-null  int64  \n",
      " 8   points_redeemed              403760 non-null  int64  \n",
      " 9   dollar_cost_points_redeemed  403760 non-null  float64\n",
      " 10  country                      403760 non-null  object \n",
      " 11  province                     403760 non-null  object \n",
      " 12  city                         403760 non-null  object \n",
      " 13  postal_code                  403760 non-null  object \n",
      " 14  gender                       403760 non-null  object \n",
      " 15  education                    403760 non-null  object \n",
      " 16  salary                       403760 non-null  float64\n",
      " 17  marital_status               403760 non-null  object \n",
      " 18  loyalty_card                 403760 non-null  object \n",
      " 19  customer_lifetime_value      403760 non-null  float64\n",
      " 20  enrollment_type              403760 non-null  object \n",
      " 21  enrollment_year              403760 non-null  int64  \n",
      " 22  enrollment_month             403760 non-null  int64  \n",
      " 23  cancellation_year            49650 non-null   Int64  \n",
      " 24  cancellation_month           49650 non-null   Int64  \n",
      " 25  customer_status              403760 non-null  object \n",
      "dtypes: Int64(2), float64(4), int64(10), object(10)\n",
      "memory usage: 83.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f45b92",
   "metadata": {},
   "source": [
    "#### **9. EXPORTACIÓN DEL DATASET LIMPIO**\n",
    "\n",
    "- Se guarda el csv limpio y procesado en `data/processed/` para su reutilización en análisis posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e65cd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset limpio exportado a: ../data/processed/customer_loyalty_clean.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../data/processed/customer_loyalty_clean.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset limpio exportado a: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
